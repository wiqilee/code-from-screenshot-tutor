# Code-from-Screenshot Tutor

**By Wiqi Lee â€” Twitter: [@wiqi_lee](https://twitter.com/wiqi_lee)**  

An advanced toolkit that turns **code screenshots** into **clean code, explanations, refactors, and comparisons**.  
Supports both **OpenAI GPT models** and **local HuggingFace models** for flexible experimentation.

---

## âœ¨ Features
- ğŸ–¼ï¸ OCR code extraction (EasyOCR)
- ğŸŒ Automatic language detection
- ğŸ¤– LLM-powered explanations (OpenAI or local)
- ğŸ› ï¸ Refactor with modern best practices
- ğŸ” Compare two code screenshots side by side
- ğŸ“‚ Export to `.py`, `.js`, `.cpp`
- âš¡ REST API, Gradio Web demo, and CLI

---

## ğŸš€ Quickstart

```bash
# 1. Setup virtual environment
python -m venv .venv && source .venv/bin/activate

# 2. Install dependencies
pip install -r requirements.txt

# 3. Run FastAPI backend
uvicorn tutor.api:app --reload --port 8010

# 4. Run Gradio web demo
python -m tutor.webapp
```

---

## ğŸ”Œ Endpoints

- `GET /health` â†’ Health check  
- `POST /v1/ocr` â†’ Extract code from screenshot  
- `POST /v1/explain` â†’ Explain extracted code step by step  
- `POST /v1/refactor` â†’ Refactor code with best practices  

---

## ğŸ“Š Example Workflows
1. Upload a screenshot of Python code â†’ get OCR text.  
2. Use `/v1/explain` to receive detailed explanation from GPT-4o or TinyLlama.  
3. Use `/v1/refactor` to generate a cleaner, modernized version of the code.  
4. Compare outputs between OpenAI and HuggingFace backends.  

---

## ğŸ·ï¸ Tech Stack
- Python 3.12+  
- [FastAPI](https://fastapi.tiangolo.com/) â€” API server  
- [Gradio](https://www.gradio.app/) â€” web UI  
- [EasyOCR](https://github.com/JaidedAI/EasyOCR) â€” OCR engine  
- [Transformers](https://huggingface.co/transformers) â€” local models  
- [OpenAI](https://platform.openai.com/) â€” GPT integration  

---

## ğŸ“œ License
MIT License â€” feel free to fork, modify, and build upon.  
